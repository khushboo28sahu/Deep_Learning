{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Class_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPmKnqJ6Sqhw"
      },
      "source": [
        "### **Load Libraries and Seed Random Number Generator**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t91obJMAKSgX"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK-6oJJN2cqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2baa889c-5e3e-4ec8-e967-37babc214946"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "print(numpy.random.seed(7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyHQLAauKtnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e05fb9d-4d2a-4859-abbf-c88548b2bac9"
      },
      "source": [
        "import numpy\n",
        "print(numpy.random.seed(1)) ;\n",
        "numpy.random.rand(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.17022005e-01, 7.20324493e-01, 1.14374817e-04, 3.02332573e-01,\n",
              "       1.46755891e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VePCr8uziVZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e57546a-783e-4cfb-9e19-497ce7061d82"
      },
      "source": [
        "numpy.random.random(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09233859, 0.18626021, 0.34556073, 0.39676747, 0.53881673,\n",
              "       0.41919451, 0.6852195 , 0.20445225, 0.87811744, 0.02738759])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNzZ1rfoLSJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4743e6a1-1b22-44d7-bc9d-ab9636634d63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JcicsnKKY3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1de3b6-6dce-4c7b-825b-9604413d1497"
      },
      "source": [
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/drive/MyDrive/Git_Repository/Deep_Learning/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input and output variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2nZ-AYdKgPz"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i9JSfcQLtgx"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAmt1ITnLyx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09981a3-07f7-4f5e-baa0-5e5da2ddb065"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=1)\n",
        "#model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 2s 4ms/step - loss: 2.2884 - accuracy: 0.4909\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 1.2763 - accuracy: 0.5833\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 1.0523 - accuracy: 0.6029\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.9024 - accuracy: 0.6146\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.6315\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.8102 - accuracy: 0.6263\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.7329 - accuracy: 0.6641\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.7220 - accuracy: 0.6693\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.6654\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.6641\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6615\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6745\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.6706\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6849\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6589\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6849\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6875\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.7083\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6797\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6810\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6719\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.6589\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6875\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6927\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6927\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7070\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.6901\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6992\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.7201\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.7161\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6862\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7331\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6914\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6654\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.7174\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6992\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.7148\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.7135\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7174\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7292\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7096\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7018\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.7318\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.7109\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7148\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7148\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7214\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.7148\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7214\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7044\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7109\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.6979\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7148\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7070\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7357\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7031\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7370\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7096\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7396\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.7148\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7318\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7188\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7201\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7214\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7383\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7357\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7344\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7318\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7148\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6992\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7253\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7135\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7526\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7227\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7227\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7096\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7396\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7253\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7396\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7370\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7292\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7396\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7435\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7344\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7422\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7383\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7487\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7383\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7500\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7435\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7214\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7435\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7240\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7383\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7461\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7422\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7357\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7422\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7174\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7383\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7500\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7513\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7461\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7487\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7396\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7344\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7409\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7357\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7578\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7617\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7552\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7357\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7305\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7513\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7617\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7578\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7409\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7331\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7448\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7617\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7578\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7474\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7500\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7682\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7604\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7630\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7487\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7630\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7539\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7643\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7617\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7513\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7500\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7578\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7539\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7526\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7305\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7500\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7565\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7708\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7591\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7578\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7617\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7656\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7760\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7604\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7487\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7578\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7565\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7526\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9eb0735790>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URtjmPgTL1pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a80c202-9bc0-4757-c6e9-ba705e7039c2"
      },
      "source": [
        "#evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7682\n",
            "\n",
            "accuracy: 76.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsaGkV4MVAmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6de8a6-b0fa-4d2a-a252-5558fc6e4fda"
      },
      "source": [
        "#print(scores)\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48249760270118713, 0.7682291865348816]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0_AuFVxw_t"
      },
      "source": [
        "#**Evaluate The Performance of Deep Learning Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Manual Validation Set"
      ],
      "metadata": {
        "id": "8LHvfUke79Ww"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJv4m9EHMJRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f0f5c6-2f3f-42fc-9d77-2e54f073e7ec"
      },
      "source": [
        "# MLP with manual validation set\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/drive/MyDrive/Git_Repository/Deep_Learning/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# split into 67% for train and 33% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "52/52 [==============================] - 1s 9ms/step - loss: 4.3481 - accuracy: 0.4767 - val_loss: 1.9105 - val_accuracy: 0.6102\n",
            "Epoch 2/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 1.7783 - accuracy: 0.5914 - val_loss: 1.4228 - val_accuracy: 0.5827\n",
            "Epoch 3/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.3807 - accuracy: 0.5759 - val_loss: 1.1272 - val_accuracy: 0.6299\n",
            "Epoch 4/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 1.1430 - accuracy: 0.5973 - val_loss: 0.9921 - val_accuracy: 0.5748\n",
            "Epoch 5/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 1.0137 - accuracy: 0.6089 - val_loss: 0.8807 - val_accuracy: 0.6417\n",
            "Epoch 6/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.9229 - accuracy: 0.6206 - val_loss: 0.8397 - val_accuracy: 0.6339\n",
            "Epoch 7/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.8580 - accuracy: 0.6226 - val_loss: 0.7886 - val_accuracy: 0.6063\n",
            "Epoch 8/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7915 - accuracy: 0.6245 - val_loss: 0.8065 - val_accuracy: 0.6457\n",
            "Epoch 9/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7542 - accuracy: 0.6479 - val_loss: 0.7437 - val_accuracy: 0.6457\n",
            "Epoch 10/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.6770 - val_loss: 0.7635 - val_accuracy: 0.6614\n",
            "Epoch 11/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.6693 - val_loss: 0.7073 - val_accuracy: 0.6339\n",
            "Epoch 12/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.6479 - val_loss: 0.7099 - val_accuracy: 0.6378\n",
            "Epoch 13/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.6615 - val_loss: 0.6813 - val_accuracy: 0.6299\n",
            "Epoch 14/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6887 - val_loss: 0.6591 - val_accuracy: 0.6496\n",
            "Epoch 15/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.6576 - val_loss: 0.6529 - val_accuracy: 0.6496\n",
            "Epoch 16/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.6595 - val_loss: 0.6540 - val_accuracy: 0.6614\n",
            "Epoch 17/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.6732 - val_loss: 0.6446 - val_accuracy: 0.6457\n",
            "Epoch 18/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7062 - val_loss: 0.6326 - val_accuracy: 0.6496\n",
            "Epoch 19/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5826 - accuracy: 0.7160 - val_loss: 0.6259 - val_accuracy: 0.6772\n",
            "Epoch 20/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.6887 - val_loss: 0.6650 - val_accuracy: 0.6614\n",
            "Epoch 21/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7082 - val_loss: 0.6136 - val_accuracy: 0.6535\n",
            "Epoch 22/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5682 - accuracy: 0.7023 - val_loss: 0.6186 - val_accuracy: 0.6575\n",
            "Epoch 23/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7004 - val_loss: 0.6077 - val_accuracy: 0.6772\n",
            "Epoch 24/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7082 - val_loss: 0.6071 - val_accuracy: 0.6693\n",
            "Epoch 25/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5692 - accuracy: 0.7237 - val_loss: 0.6594 - val_accuracy: 0.6614\n",
            "Epoch 26/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5614 - accuracy: 0.7023 - val_loss: 0.6668 - val_accuracy: 0.6378\n",
            "Epoch 27/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7335 - val_loss: 0.6185 - val_accuracy: 0.6811\n",
            "Epoch 28/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.6946 - val_loss: 0.6493 - val_accuracy: 0.6890\n",
            "Epoch 29/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7179 - val_loss: 0.6314 - val_accuracy: 0.6693\n",
            "Epoch 30/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7276 - val_loss: 0.6328 - val_accuracy: 0.6654\n",
            "Epoch 31/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7198 - val_loss: 0.6005 - val_accuracy: 0.6811\n",
            "Epoch 32/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7315 - val_loss: 0.5861 - val_accuracy: 0.7087\n",
            "Epoch 33/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.7062 - val_loss: 0.6406 - val_accuracy: 0.6496\n",
            "Epoch 34/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7160 - val_loss: 0.6079 - val_accuracy: 0.6732\n",
            "Epoch 35/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.7101 - val_loss: 0.6021 - val_accuracy: 0.6654\n",
            "Epoch 36/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7393 - val_loss: 0.5890 - val_accuracy: 0.6811\n",
            "Epoch 37/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7101 - val_loss: 0.6287 - val_accuracy: 0.6496\n",
            "Epoch 38/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7257 - val_loss: 0.6104 - val_accuracy: 0.6850\n",
            "Epoch 39/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7160 - val_loss: 0.6942 - val_accuracy: 0.6575\n",
            "Epoch 40/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7101 - val_loss: 0.5910 - val_accuracy: 0.6732\n",
            "Epoch 41/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7315 - val_loss: 0.5843 - val_accuracy: 0.7165\n",
            "Epoch 42/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7432 - val_loss: 0.5786 - val_accuracy: 0.7126\n",
            "Epoch 43/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7276 - val_loss: 0.5868 - val_accuracy: 0.6811\n",
            "Epoch 44/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7276 - val_loss: 0.5952 - val_accuracy: 0.6772\n",
            "Epoch 45/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7276 - val_loss: 0.5941 - val_accuracy: 0.6654\n",
            "Epoch 46/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7412 - val_loss: 0.6311 - val_accuracy: 0.6575\n",
            "Epoch 47/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7082 - val_loss: 0.5900 - val_accuracy: 0.6654\n",
            "Epoch 48/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7393 - val_loss: 0.6703 - val_accuracy: 0.6535\n",
            "Epoch 49/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5468 - accuracy: 0.7276 - val_loss: 0.6142 - val_accuracy: 0.6614\n",
            "Epoch 50/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7471 - val_loss: 0.5965 - val_accuracy: 0.7126\n",
            "Epoch 51/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7393 - val_loss: 0.5844 - val_accuracy: 0.6614\n",
            "Epoch 52/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7335 - val_loss: 0.5744 - val_accuracy: 0.6811\n",
            "Epoch 53/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7179 - val_loss: 0.5922 - val_accuracy: 0.7047\n",
            "Epoch 54/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7160 - val_loss: 0.5750 - val_accuracy: 0.6969\n",
            "Epoch 55/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7432 - val_loss: 0.5764 - val_accuracy: 0.7165\n",
            "Epoch 56/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7549 - val_loss: 0.5678 - val_accuracy: 0.7244\n",
            "Epoch 57/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7451 - val_loss: 0.5729 - val_accuracy: 0.6811\n",
            "Epoch 58/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7412 - val_loss: 0.5679 - val_accuracy: 0.7362\n",
            "Epoch 59/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7529 - val_loss: 0.5661 - val_accuracy: 0.6850\n",
            "Epoch 60/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7607 - val_loss: 0.5896 - val_accuracy: 0.6654\n",
            "Epoch 61/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7179 - val_loss: 0.5856 - val_accuracy: 0.6811\n",
            "Epoch 62/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7607 - val_loss: 0.5651 - val_accuracy: 0.7362\n",
            "Epoch 63/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7510 - val_loss: 0.5679 - val_accuracy: 0.7283\n",
            "Epoch 64/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7490 - val_loss: 0.5733 - val_accuracy: 0.7362\n",
            "Epoch 65/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5012 - accuracy: 0.7257 - val_loss: 0.5679 - val_accuracy: 0.6969\n",
            "Epoch 66/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7607 - val_loss: 0.5800 - val_accuracy: 0.7165\n",
            "Epoch 67/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7179 - val_loss: 0.5595 - val_accuracy: 0.7244\n",
            "Epoch 68/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7471 - val_loss: 0.5727 - val_accuracy: 0.7362\n",
            "Epoch 69/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7529 - val_loss: 0.5638 - val_accuracy: 0.7402\n",
            "Epoch 70/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7626 - val_loss: 0.5813 - val_accuracy: 0.6850\n",
            "Epoch 71/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.7510 - val_loss: 0.5612 - val_accuracy: 0.7402\n",
            "Epoch 72/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7646 - val_loss: 0.5658 - val_accuracy: 0.7362\n",
            "Epoch 73/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7510 - val_loss: 0.5687 - val_accuracy: 0.6850\n",
            "Epoch 74/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7549 - val_loss: 0.5720 - val_accuracy: 0.7126\n",
            "Epoch 75/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7646 - val_loss: 0.5821 - val_accuracy: 0.7047\n",
            "Epoch 76/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7588 - val_loss: 0.5677 - val_accuracy: 0.7008\n",
            "Epoch 77/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7685 - val_loss: 0.6008 - val_accuracy: 0.7087\n",
            "Epoch 78/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7685 - val_loss: 0.5590 - val_accuracy: 0.7165\n",
            "Epoch 79/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7588 - val_loss: 0.6100 - val_accuracy: 0.6890\n",
            "Epoch 80/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7490 - val_loss: 0.5787 - val_accuracy: 0.6850\n",
            "Epoch 81/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7646 - val_loss: 0.5755 - val_accuracy: 0.7087\n",
            "Epoch 82/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7432 - val_loss: 0.5531 - val_accuracy: 0.7205\n",
            "Epoch 83/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7510 - val_loss: 0.6021 - val_accuracy: 0.7008\n",
            "Epoch 84/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7724 - val_loss: 0.6026 - val_accuracy: 0.7087\n",
            "Epoch 85/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7724 - val_loss: 0.5652 - val_accuracy: 0.7008\n",
            "Epoch 86/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7412 - val_loss: 0.5654 - val_accuracy: 0.7205\n",
            "Epoch 87/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7451 - val_loss: 0.5578 - val_accuracy: 0.7165\n",
            "Epoch 88/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7471 - val_loss: 0.6007 - val_accuracy: 0.6969\n",
            "Epoch 89/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7471 - val_loss: 0.5723 - val_accuracy: 0.7087\n",
            "Epoch 90/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7607 - val_loss: 0.5684 - val_accuracy: 0.7126\n",
            "Epoch 91/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4871 - accuracy: 0.7451 - val_loss: 0.5719 - val_accuracy: 0.7008\n",
            "Epoch 92/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7510 - val_loss: 0.6264 - val_accuracy: 0.6732\n",
            "Epoch 93/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7588 - val_loss: 0.5569 - val_accuracy: 0.7441\n",
            "Epoch 94/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7432 - val_loss: 0.5688 - val_accuracy: 0.7087\n",
            "Epoch 95/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7529 - val_loss: 0.5567 - val_accuracy: 0.7205\n",
            "Epoch 96/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7763 - val_loss: 0.5736 - val_accuracy: 0.7047\n",
            "Epoch 97/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7724 - val_loss: 0.6140 - val_accuracy: 0.7008\n",
            "Epoch 98/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7568 - val_loss: 0.5756 - val_accuracy: 0.6929\n",
            "Epoch 99/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7588 - val_loss: 0.5840 - val_accuracy: 0.7126\n",
            "Epoch 100/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7510 - val_loss: 0.5652 - val_accuracy: 0.7244\n",
            "Epoch 101/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7510 - val_loss: 0.5715 - val_accuracy: 0.6929\n",
            "Epoch 102/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4795 - accuracy: 0.7626 - val_loss: 0.5815 - val_accuracy: 0.7244\n",
            "Epoch 103/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7607 - val_loss: 0.5802 - val_accuracy: 0.6929\n",
            "Epoch 104/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7665 - val_loss: 0.5566 - val_accuracy: 0.7244\n",
            "Epoch 105/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7802 - val_loss: 0.5557 - val_accuracy: 0.7047\n",
            "Epoch 106/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7763 - val_loss: 0.5530 - val_accuracy: 0.7165\n",
            "Epoch 107/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7763 - val_loss: 0.5962 - val_accuracy: 0.7126\n",
            "Epoch 108/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7724 - val_loss: 0.5822 - val_accuracy: 0.7244\n",
            "Epoch 109/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7782 - val_loss: 0.5580 - val_accuracy: 0.7323\n",
            "Epoch 110/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7626 - val_loss: 0.5666 - val_accuracy: 0.7165\n",
            "Epoch 111/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7529 - val_loss: 0.5664 - val_accuracy: 0.7165\n",
            "Epoch 112/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7821 - val_loss: 0.5840 - val_accuracy: 0.7087\n",
            "Epoch 113/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7782 - val_loss: 0.5707 - val_accuracy: 0.7126\n",
            "Epoch 114/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7704 - val_loss: 0.5579 - val_accuracy: 0.7323\n",
            "Epoch 115/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7685 - val_loss: 0.5763 - val_accuracy: 0.7087\n",
            "Epoch 116/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7549 - val_loss: 0.5735 - val_accuracy: 0.7165\n",
            "Epoch 117/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7685 - val_loss: 0.6404 - val_accuracy: 0.6811\n",
            "Epoch 118/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7646 - val_loss: 0.5563 - val_accuracy: 0.7126\n",
            "Epoch 119/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7782 - val_loss: 0.5790 - val_accuracy: 0.7126\n",
            "Epoch 120/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7840 - val_loss: 0.6195 - val_accuracy: 0.6772\n",
            "Epoch 121/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7626 - val_loss: 0.5755 - val_accuracy: 0.7323\n",
            "Epoch 122/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
            "Epoch 123/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.7802 - val_loss: 0.5601 - val_accuracy: 0.7126\n",
            "Epoch 124/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7704 - val_loss: 0.5590 - val_accuracy: 0.7126\n",
            "Epoch 125/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7626 - val_loss: 0.5843 - val_accuracy: 0.7008\n",
            "Epoch 126/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7607 - val_loss: 0.5738 - val_accuracy: 0.7126\n",
            "Epoch 127/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.5701 - val_accuracy: 0.7165\n",
            "Epoch 128/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7821 - val_loss: 0.5950 - val_accuracy: 0.7087\n",
            "Epoch 129/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5746 - val_accuracy: 0.7165\n",
            "Epoch 130/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7529 - val_loss: 0.6254 - val_accuracy: 0.6890\n",
            "Epoch 131/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7763 - val_loss: 0.5672 - val_accuracy: 0.6890\n",
            "Epoch 132/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7840 - val_loss: 0.5586 - val_accuracy: 0.7244\n",
            "Epoch 133/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7607 - val_loss: 0.6028 - val_accuracy: 0.7205\n",
            "Epoch 134/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7860 - val_loss: 0.5648 - val_accuracy: 0.7165\n",
            "Epoch 135/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7840 - val_loss: 0.5597 - val_accuracy: 0.7126\n",
            "Epoch 136/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7763 - val_loss: 0.5761 - val_accuracy: 0.7008\n",
            "Epoch 137/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7607 - val_loss: 0.5604 - val_accuracy: 0.7362\n",
            "Epoch 138/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7704 - val_loss: 0.5597 - val_accuracy: 0.7244\n",
            "Epoch 139/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7899 - val_loss: 0.5563 - val_accuracy: 0.7283\n",
            "Epoch 140/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7918 - val_loss: 0.5775 - val_accuracy: 0.7244\n",
            "Epoch 141/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7879 - val_loss: 0.5648 - val_accuracy: 0.7087\n",
            "Epoch 142/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7860 - val_loss: 0.5661 - val_accuracy: 0.7126\n",
            "Epoch 143/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7938 - val_loss: 0.5699 - val_accuracy: 0.7126\n",
            "Epoch 144/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7782 - val_loss: 0.5622 - val_accuracy: 0.7402\n",
            "Epoch 145/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7918 - val_loss: 0.5870 - val_accuracy: 0.7283\n",
            "Epoch 146/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7704 - val_loss: 0.6178 - val_accuracy: 0.6969\n",
            "Epoch 147/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7685 - val_loss: 0.5831 - val_accuracy: 0.7165\n",
            "Epoch 148/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7704 - val_loss: 0.6383 - val_accuracy: 0.6772\n",
            "Epoch 149/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7704 - val_loss: 0.5800 - val_accuracy: 0.7205\n",
            "Epoch 150/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7626 - val_loss: 0.5773 - val_accuracy: 0.7362\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e4484cad0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQmrlb_hAZeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a43f6e7-83f0-4336-cb54-3bda09f20957"
      },
      "source": [
        "scores = model.evaluate(X, Y)\n",
        "#print(scores)\n",
        "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7669\n",
            "\n",
            "accuracy: 76.6927%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlVlp714ly3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b999d79-6202-427e-dff5-031041f25166"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "print(StratifiedKFold(n_splits=10, shuffle=True, random_state=7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=7, shuffle=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K- Fold Cross Validation"
      ],
      "metadata": {
        "id": "80QS1xbz7FQL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lO9GvUGGvgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554b6e90-bebf-41ea-c680-1b9cfc01ecf0"
      },
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/drive/MyDrive/Git_Repository/Deep_Learning/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
        "    \n",
        "    # evaluate the model\n",
        "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 74.03%\n",
            "accuracy: 67.53%\n",
            "accuracy: 70.13%\n",
            "WARNING:tensorflow:5 out of the last 34 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9e40654830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "accuracy: 70.13%\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9e43409a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "accuracy: 66.23%\n",
            "accuracy: 67.53%\n",
            "accuracy: 76.62%\n",
            "accuracy: 75.32%\n",
            "accuracy: 73.68%\n",
            "accuracy: 76.32%\n",
            "71.75% (+/- 3.71%)\n"
          ]
        }
      ]
    }
  ]
}